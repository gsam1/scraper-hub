# scraper-hub

## 1. Motivation
A lot of my Data Science/Machine Learning projects require scraping a web pages and storing them in a database or as raw files. In addition the steps to clean and detecting faulty entries in the data are tedious so I wanted to adhere to the principle of code once - use it again everywhere and write some anomaly detection into the pipeline of scraping a page - storing into a db in a proper format.

## 2. Structure
1. Admin - controls hosts and negotiate resources, needed for the scraped data.
2. Ingestion - API endpoint to receive the data from the various scrapers.


## 3. Status
Nothing ready...